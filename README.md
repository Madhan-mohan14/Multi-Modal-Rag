# ğŸ¤– Multi-Doc Pro: Multi-Modal RAG Agent v2.0

![Python](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-UI-ff4b4b?logo=streamlit&logoColor=white)
![LangChain](https://img.shields.io/badge/LangChain-Framework-1C3C3C?logo=langchain&logoColor=white)
![LlamaParse](https://img.shields.io/badge/LlamaParse-Vision%20AI-000000)
![Ragas](https://img.shields.io/badge/Ragas-Evaluation-orange)
![License](https://img.shields.io/badge/License-Proprietary-red)

> **"Standard RAG is blind to charts. Multi-Doc Pro can see."**

A production-grade Retrieval-Augmented Generation (RAG) system engineered to process **complex financial documents** (like IMF Reports) containing dense tables, charts, and figures. 

Unlike traditional pipelines that strip away visual context, this system uses **Vision-Language Models (GPT-4o-mini)** to parse visual data and **FlashRank Re-ranking** to ensure high-precision retrieval.

---

## ğŸ—ï¸ System Architecture

The pipeline follows a **"Parse-Then-Chunk"** architecture optimized for preserving document structure.
---<img width="2816" height="1536" alt="Gemini_Generated_Image_2lty912lty912lty" src="https://github.com/user-attachments/assets/f7b34336-d969-49c9-af3e-725a1d6942c8" />

## ğŸ“‚ Project Structure

```text
MULTI-DOC-PRO/
â”‚
â”œâ”€â”€ ğŸ“ .streamlit/            # Streamlit UI configuration (Theme, Colors)
â”œâ”€â”€ ğŸ“ data/                  # Raw Data Storage (PDFs/Images)
â”‚   â””â”€â”€ ğŸ“„ qatar_imf.pdf      # (Sample) Financial Report for Testing
â”œâ”€â”€ ğŸ“ persist/               # ChromaDB Vector Store (Persistent Embeddings)
â”œâ”€â”€ ğŸ“ venv/                  # Python Virtual Environment
â”‚
â”œâ”€â”€ ğŸ“„ app.py                 # ğŸš€ Main Application Entry Point (Streamlit UI)
â”œâ”€â”€ ğŸ“„ setup_db.py            # ğŸ› ï¸ Database Initialization Script (Runs Ingestion)
â”‚
â”œâ”€â”€ ğŸ§  Core Logic Modules
â”‚   â”œâ”€â”€ ğŸ“„ chain_handler.py        # RAG Logic: Query Rewriting, Re-ranking, & Generation
â”‚   â”œâ”€â”€ ğŸ“„ data_loader.py          # Smart Chunking: Markdown & Recursive Splitters
â”‚   â”œâ”€â”€ ğŸ“„ vector_store_handler.py # Database: ChromaDB Management & Embedding
â”‚   â”œâ”€â”€ ğŸ“„ file_handler.py         # Router: Determines file types (PDF vs Text)
â”‚   â””â”€â”€ ğŸ“„ llama_parser_handler.py # Vision AI: LlamaParse + GPT-4o-mini Integration
â”‚
â”œâ”€â”€ ğŸ”§ Utilities
â”‚   â””â”€â”€ ğŸ“„ multimodal_utils.py     # Helpers: Markdown Cleanup & Filename Sanitization
â”‚
â”œâ”€â”€ âš–ï¸ Evaluation Suite
â”‚   â”œâ”€â”€ ğŸ“„ evaluate.py             # Ragas Config: Automated Grading Logic
â”‚   â”œâ”€â”€ ğŸ“„ finish_grading.py       # Safe-Mode Grader: Runs metrics with rate-limiting
â”‚   â”œâ”€â”€ ğŸ“„ pre_eval_backup.csv     # Intermediate results cache
â”‚   â””â”€â”€ ğŸ“„ evaluation_report.csv   # Final Accuracy Scores
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt       # Project Dependencies
â””â”€â”€ ğŸ“„ .env                   # API Keys (Excluded from Git)
```
---

## ğŸŒŸ Key Features
| **Feature**                 | **Description**                                                    | **Tech Stack**             |
| --------------------------- | ------------------------------------------------------------------ | -------------------------- |
| ``ğŸ‘€ Multi-Modal Vision``   | Parses PDFs as images to extract charts & tables into Markdown.    | LlamaParse, GPT-4o-mini    |
| ``ğŸ§  Smart Chunking ``      | Splits text by Markdown headers to preserve logical sections.      | MarkdownHeaderTextSplitter |
| ``ğŸ¯ Precision Retrieval ``| Uses a Two-Stage retrieval process (Vector Search + Reranking).    | ChromaDB, FlashRank        |
|`` ğŸ›¡ï¸ Hallucination Guard``| Answers are strictly grounded in retrieved context with citations. | LangChain, Llama-3.3-70b   |
|`` âš–ï¸ Automated Eval``     | Self-grading pipeline to measure Faithfulness and Accuracy.        | Ragas Framework            |

---
##ğŸš€ Getting Started(local deployment)

### ğŸ› ï¸ Requirements
* Python 3.10+
* A `GROQ_API_KEY` (for fast inference)
* A `GOOGLE_API_KEY` (for embeddings)
* A `LLAMA_CLOUD_API_KEY` (for llama parse)

### Setup

1.  **Clone the repository & install dependencies:**
    ```bash
    git clone [https://github.com/Madhan-mohan14/Multi-Modal-Rag.git](https://github.com/Madhan-mohan14/Multi-Modal-Rag.git)
    cd Multi-Modal-Rag
    pip install -r requirements.txt 
    ```

2.  **Set Environment Variables:** Create a `.env` file in the root directory:
       ```
    GROQ_API_KEY="YOUR_GROQ_KEY"
    GOOGLE_API_KEY="YOUR_GOOGLE_KEY"
    LLAMA_CLOUD_API_KEY="YOUR_GOOGLE_KEY"
    ```
3.  **Run the App:**
4.  first you have to run the setup_db.py to load the documents which we have and pre index them 
    ```bash
     python setup_db.py
    streamlit run app.py
    ```
5. for evaluation
   ```bash
   python finish_grading.py
   ```
---
## ğŸ“Š Evaluation Results
This system was rigorously tested using the Ragas framework against a "Golden Dataset" derived from the IMF Qatar Article IV Report.

ğŸ† Score: 78% Faithfulness
The system demonstrates high reliability (0.78), correctly refusing to answer when data is missing (e.g., specific regulatory measures vs. objectives), effectively mitigating hallucinations.

## ğŸ“œ License
Proprietary & Confidential. Copyright (c) 2025 Madhan Mohan. All Rights Reserved.

Permitted: Viewing for educational/evaluation purposes.

Prohibited: Commercial use, modification, or redistribution without permission.
## ğŸ”® Future Roadmap

* **ğŸ—£ï¸ Audio Querying:** Integrate OpenAI Whisper to allow users to ask questions via voice instead of typing.
* **ğŸ” Hybrid Search:** Implement BM25 + Vector Search (Reciprocal Rank Fusion) to better capture specific acronyms and keywords.
* **â˜ï¸ Cloud Native:** Dockerize the application and migrate to serverless vector databases (Pinecone/Weaviate) for enterprise scaling.
* **ğŸ•¸ï¸ GraphRAG:** Add Knowledge Graphs to link disconnected entities across documents for complex multi-hop reasoning.
* **ğŸ•µï¸ Agentic Workflow:** Upgrade to LangGraph agents that can self-correct poor retrieval results and validate data with external tools and also user can ask related to the previous questions and maintain history.
